# Knowledge-Base â€” Architecture

Cloud-first KB service: ingest from Google Drive via api-gateway, store vectors in PostgreSQL (pgvector), hybrid retrieval (dense + FTS â†’ RRF â†’ Voyage rerank).

**Color key:** ðŸ”µ Caller &nbsp;|&nbsp; ðŸŸ¢ Routes &nbsp;|&nbsp; ðŸŒ¿ RAG / Search &nbsp;|&nbsp; ðŸŸ¡ Ingest &nbsp;|&nbsp; ðŸŸ£ LLM Gateway &nbsp;|&nbsp; ðŸ’™ Database &nbsp;|&nbsp; ðŸŸ  External

```mermaid
flowchart TB
    classDef caller    fill:#dbeafe,stroke:#3b82f6,color:#1e3a8a,font-weight:bold
    classDef router    fill:#ccfbf1,stroke:#14b8a6,color:#134e4a,font-weight:bold
    classDef ragNode   fill:#d1fae5,stroke:#10b981,color:#064e3b,font-weight:bold
    classDef ingest    fill:#fef9c3,stroke:#ca8a04,color:#713f12,font-weight:bold
    classDef llmNode   fill:#ede9fe,stroke:#8b5cf6,color:#3b0764
    classDef dbNode    fill:#e0e7ff,stroke:#6366f1,color:#1e1b4b,font-weight:bold
    classDef extNode   fill:#ffedd5,stroke:#f97316,color:#7c2d12,font-weight:bold

    subgraph CALLER["  Caller  "]
        gw_proxy["api-gateway\n/kb/* proxy"]
    end

    subgraph KB["  Knowledge-base Service â€” FastAPI  "]

        subgraph ROUTES["  Routes â€” /v1/* (auth required)  "]
            r_health["/health â€” public"]
            r_llm["/chat/completions Â· /models"]
            r_search["/kb/search Â· /kb/stats"]
            r_ingest["/kb/sync Â· /kb/sources\n/kb/files Â· DELETE /kb"]
            r_cfg["/config â€” GET Â· PATCH"]
        end

        subgraph RAG["  Search â€” RAG Pipeline  "]
            qproc["query_processor\noptional LLM query expansion\nvia gateway before embed"]
            retriever["retriever\ndense_search  HNSW cosine\n+ fts_search  GIN plainto_tsquery\nâ†’ RRF fusion  k=60"]
            embedder["embedder\nembed_query Â· embed_documents\nVoyage AI  Â·  batch size 96\nasyncio.to_thread"]
            reranker["reranker\nVoyage rerank-2.5\nasyncio.to_thread"]
        end

        subgraph INGEST["  Ingest Pipeline  "]
            sync["sync.py â€” sync_drive\nincremental by default\nforce=True re-syncs all"]
            loader["loader\nlist_drive_files Â· download_file\nparse: PDF Â· DOCX Â· text\nCSV Â· markdown Â· xlsx"]
            chunking["chunking\nlangchain-text-splitters"]
        end

        subgraph LLM["  LLM Gateway  "]
            ai_gw["llm/gateway.py â€” AIGateway\nsynchronous httpx client\nâ†’ /ai/v1/chat/completions"]
        end

    end

    subgraph DB["  PostgreSQL + pgvector  "]
        chunks[("kb_chunks\ncontent Â· embedding vector(1024)\nfts tsvector (auto) Â· source_category\ndrive_file_id Â· filename Â· chunk_index\nIndex: HNSW Â· GIN Â· btree")]
        sources[("kb_sources\nfile_id PK Â· filename Â· category\nmodified_time Â· last_synced\nchunk_count Â· status")]
    end

    GW["api-gateway\nAPI_GATEWAY_URL + X-API-Key"]
    VOYAGE["Voyage AI\nembed-2 Â· rerank-2.5"]

    gw_proxy --> r_search
    gw_proxy --> r_ingest

    r_search --> qproc
    qproc -->|"optional"| ai_gw
    r_search --> retriever
    retriever --> embedder
    retriever --> reranker
    reranker -->|"threshold filter â†’ top_k"| retriever

    ai_gw -->|"POST /ai/v1/chat/completions"| GW
    embedder -->|"embed_query / embed_documents"| VOYAGE
    reranker -->|"rerank-2.5"| VOYAGE

    r_ingest --> sync
    sync -->|"GET /storage/files\n(all 5 KB subfolders)"| GW
    sync --> loader
    loader -->|"GET /storage/files/{id}/content"| GW
    loader --> chunking
    chunking --> embedder
    sync -->|"atomic: DELETE old + INSERT new"| chunks
    sync -->|"upsert on sync"| sources

    class gw_proxy caller
    class r_health,r_llm,r_search,r_ingest,r_cfg router
    class qproc,retriever,embedder,reranker ragNode
    class sync,loader,chunking ingest
    class ai_gw llmNode
    class chunks,sources dbNode
    class GW,VOYAGE extNode

    style CALLER  fill:#eff6ff,stroke:#3b82f6,color:#1e3a8a
    style KB      fill:#f8fafc,stroke:#cbd5e1,color:#0f172a
    style ROUTES  fill:#f0fdfa,stroke:#14b8a6,color:#134e4a
    style RAG     fill:#ecfdf5,stroke:#10b981,color:#064e3b
    style INGEST  fill:#fefce8,stroke:#ca8a04,color:#713f12
    style LLM     fill:#faf5ff,stroke:#8b5cf6,color:#3b0764
    style DB      fill:#eef2ff,stroke:#6366f1,color:#1e1b4b
```

---

### Search flow â€” `POST /v1/kb/search`

1. **Query expansion** *(optional, `expand_query=true`)*: `QueryProcessor` calls `AIGateway.chat()` â†’ gateway `/ai/v1/chat/completions` â†’ expanded query string.
2. **Embed**: `embed_query(query)` â†’ Voyage AI (sync, `asyncio.to_thread`).
3. **Dense search**: pgvector HNSW cosine similarity, top `rerank_candidates` rows.
4. **FTS search**: PostgreSQL `plainto_tsquery` on `fts` GIN index, top `rerank_candidates` rows. Skipped if `sparse_weight = 0`.
5. **RRF fusion**: Reciprocal Rank Fusion (`k=60`) merges dense + FTS ranked lists.
6. **Rerank**: Voyage `rerank-2.5` re-scores fused candidates (sync, `asyncio.to_thread`).
7. **Filter**: drop chunks below `similarity_threshold`, return top `top_k`.

### Sync flow â€” `POST /v1/kb/sync`

| Step | Detail |
|---|---|
| **List** | `GET /storage/files` on gateway â€” returns files from all 5 KB subfolders (general, projects, purdue, career, reference) with category per file. |
| **Diff** | Compare against `kb_sources` by `file_id` + `modified_time`. Skip unchanged; mark removed files. |
| **Download** | `GET /storage/files/{id}/content` â€” gateway exports Google Docs/Sheets as plain text/xlsx. |
| **Parse** | PDF â†’ PyPDF2, DOCX â†’ python-docx, xlsx â†’ openpyxl, text/CSV/markdown â†’ raw. |
| **Chunk** | `chunk_text()` via langchain-text-splitters. |
| **Embed** | `embed_documents(chunks)` in batches of 96 â†’ Voyage AI. |
| **Write** | Atomic transaction: `DELETE` old chunks for file â†’ `INSERT` new chunks. Upsert `kb_sources`. |
| **Delete** | Files no longer in Drive: delete chunks, mark `kb_sources.status = 'deleted'`. |
